{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import PyPDFLoader \n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "Model = \"gpt-3.5-turbo\"\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=Model)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "parser = StrOutputParser()\n",
    "chain = model | parser\n",
    "chain.invoke(\"tell me a joke\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"IEEEComparativeStudy.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "template = \"\"\"\n",
    "You are professioanl in fraud detection as ML engineer.\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt.format(context=\"Here is some context\", question=\"Here is a question\")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"context\": \"My parents named me Santiago\", \"question\": \"What's your name'?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(pages, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'IEEEComparativeStudy.pdf', 'page': 3}, page_content='distribution within the folds . Meanwhile, to fill the number of \\nthe negative files, we proceed to the re -balancing of the data \\nthrough the method \"Resample\" of Weka before applying \\ntesting and learning  in each iteration, the results obtained after \\nre-balancing data are improved.  \\n5) Evaluation  \\n \\nThe efficiency and performance of the algorithms are \\ncalculated from various metrics , the most prominent are recall \\n(sensitivity ), specificity, and precision. An efficient classifier \\nshould have higher values for these indicators.  To facilitate the \\ninterpretation  of the algorithm performance, Van Rijsberjen, \\n(1979)  [21] has created a synthetic measure  F1-Measure  or F-\\nscore , defined as  the harmonic mean of the precision ( True \\nPositive Accuracy ) and recall  (True Positive Rate)  of a binary \\ndecision rule . The F -measure recognized as the most \\ncommonly used measure to assess test â€™s accuracy, applied to \\nstatistical analysis, machine learning, natural language \\nprocessing and information retrie val. \\nð¹âˆ’ð‘€ð‘’ð‘Žð‘ ð‘¢ð‘Ÿð‘’ = ((1+ð›½2)Ã—ð‘ƒð‘Ÿð‘’ð‘ð‘–ð‘ ð‘–ð‘œð‘› Ã—ð‘…ð‘’ð‘ð‘Žð‘™ð‘™ )\\n((ð›½2Ã—ð‘ƒð‘Ÿð‘’ð‘ð‘–ð‘ ð‘–ð‘œð‘› )+ð‘…ð‘’ð‘ð‘Žð‘™ð‘™ ) \\n ð›½2=1 \\nNevertheless, according to research of (Nakache and \\nMetais, 2005)  [22], the F -Measure has certain shortcoming s, \\nthey introduce a meta -measure \"K -Measure\" which is an \\noverall of F -measure and break even p oint ( Joachims, 1998)  \\n[23].  \\nð¾âˆ’ð‘€ð‘’ð‘Žð‘ ð‘¢ð‘Ÿð‘’ =(1+ð›½2 )Ã—(ð‘ƒð‘Ÿð‘’ð‘ð‘–ð‘ ð‘–ð‘œð‘› Ã—ð‘…ð‘’ð‘ð‘Žð‘™ð‘™ )ð›¼\\n((ð›½2Ã—ð‘ƒð‘Ÿð‘’ð‘ð‘–ð‘ ð‘–ð‘œð‘› )+ð‘…ð‘’ð‘ð‘Žð‘™ð‘™ ) \\n ð›½2=1,ð›¼=0,5 \\nThus, we will integrate the two measures in our study to   \\nevaluate the relevance of the algorithms and proceed to \\nclassify them according to the outcome of each measure \\nseparately.  \\nTo support the results of our study between the two \\nmeasures mentioned, we introduce another indicator  : Root \\nMean Squared Log error (RMSE) (also called the root mean \\nsquare deviation, RMSD) is commonly  used  to calculate \\nsquare difference between the prediction and target for each \\npoint, then ave rage those values into the root (Bouthevillain  \\nand Mathis, 1995 ) [24]. The higher this value, the worse the \\nmodel is . \\nð‘…ð‘€ð‘†ð¸ = âˆš1\\nð‘âˆ‘(ð›¾Ì‚ð‘–âˆ’ð›¾ð‘–)ð‘›\\nð‘–=1Â² \\nWhere ð›¾ð‘– is the actual expected output and ð›¾Ì‚ð‘– is the \\nmodelâ€™s prediction.  \\nIV. EXPERIMENTAL ANALYSIS  \\n \\n1) Simulation tools   \\n \\nFor the experimental validation, we used the Weka \\nsimulator. WEKA is an acronym for Waikato Env ironment for \\nKnowledge Analysis , developed at the University of Waikato \\nin New Zealand . It is  open -source  programming library \\nwritten in  Java with wide support  for machine \\nlearning  algorithms , able to solve a wide variety of automatic training tasks, such as data preprocessing, clustering , \\nclassification, regression and implementation.  \\n2) Experimental results  \\n \\nIn this paper , we have proposed a  comparative analysis  \\nbetween the different classification models according to the \\ntwo performance measures F -Measure and K -Measure. T he \\nRMSE indicator will also be calculated and compared with the \\nresult of the two measures; In the â€œFeatures Selection â€ \\nSection , we reduced the  number of features  from 26 to 19 to \\nkeep only the relevant features . As presented in Table 2 , \\nbefore reduction we can see that Adaboost.M1 shows the best \\nclassification score  (96.68%) using  K-Measure, but Decision  \\nTable takes the lead ( 24.7%) using F -Measure.   \\nHowever, after reducing the features , the results of F -\\nMeasure and K -measure are v isibly improved  as shown in \\nTable 3 . According to K -Measure, Random Forest keeps the \\nbest s core with 99.4% (+4%). U nlike F -Measure, Decision \\nTable keeps almost the same score 24.7% and gives up the \\nfirst place to MultilayerPerceptron with 25.6 % (+1.2%).  \\nAdmittedly, the two rankings are different or even \\nopposite, indeed RandomForest is ranked last with F -\\nMeasure, whereas  it is ranked first with K -Measure. In order \\nto judge the relevance of the two measures, we introduced the \\nRMSE indicator , as presented in Fig.2,  the result obtained \\nshows a strong rank correlation between K-measure and'),\n",
       " Document(metadata={'source': 'IEEEComparativeStudy.pdf', 'page': 3}, page_content='to judge the relevance of the two measures, we introduced the \\nRMSE indicator , as presented in Fig.2,  the result obtained \\nshows a strong rank correlation between K-measure and \\nRMSE, indeed  the lowest value is attributed to Random Forest \\nwith 29.8%. H owever MultilayerPerceptron is ranked 5th with \\n41.26%.  \\nTable 2: Comparative Performance Analysis before Feature \\nSelection on  Dataset  rebalancing:  \\nClassifier  Recall  Precision  F-measure  K-measure  \\nAdaBoostM1  12,67%  20,96%  15,72%  96,68%  \\nRandomForest  13,32%  22,28%  16,62%  96,44%  \\nPART  34,78%  15,90%  21,79%  92,78%  \\nJ48 45,61%  14,29%  21,76%  85,17%  \\nMultilayerPerceptron  63,81%  15,26%  24,40%  79,05%  \\nDecisionTable  75,83%  14,90%  24,79%  74,12%  \\nSGD  76,44%  13,57%  22,91%  71,95%  \\nLogistic  79,74%  13,39%  22,93%  70,17%  \\nNaiveBayes  84,61%  12,27%  21,44%  66,51%  \\nSVM  91,76%  12,64%  22,22%  65,24 % \\n \\nTable 3: Comparative Performance Analysis after Feature  \\nSelection on Dataset  rebalancing : \\n  Classifier  Recall  Precision  F-Measure   K - Measure  \\nRandom Forest  23,83%  19,66%  21,52%  99,46%  \\nAdaBoostM1  28,38%  17,92%  21,94%  97,34%  \\nPART  35,64%  15,51%  21,60%  91,89%  \\nJ48 45,61%  14,86%  22,40%  86,07%  \\nMultilayerPerceptron  65,12%  16,10%  25,66%  79,92%  \\nDecision Table  75,83%  14,90%  24,79%  74,12%  \\nLogistic  84,50%  13,40%  23,14%  68,75%  \\nSGD  88,52%  12,93%  22,56%  66,69%  \\n(3) \\n(1) \\n \\n(2)'),\n",
       " Document(metadata={'source': 'IEEEComparativeStudy.pdf', 'page': 4}, page_content='NaiveBayes  87,21%  12,30%  21,55%  65,81%  \\nSVM  91,76%  12,64%  22,22%  65,24%  \\n \\nFig 2: Correlation between K -Measure and RMSE . \\n \\nV. CONCLUSION  \\n \\nIn this work,  we present a comparison of the ten most \\nfrequently used machine -learning  algorithms and compare \\ntheir performance with two evaluation methods to determine \\nwhich is the most appropriate, applied to  on real  world data \\nfor fraud prediction.   \\nThe study shows that the Random Forest algorithm has the \\nbest performance with K -measure evaluation and the best \\nscore with RMSE . Radom Forest also has the best ratio \\nbetween recall and precision , the share of fraud disco vered \\namong all frauds is 23.8%. O n the other hand, we have the \\nprecision  is 19.7%  holding the highest score between models , \\nthis means that in 2/10 of the cases when a claim is predicted  \\nas fraud, the model is correct . Furthermore , if we compare \\naccuracy  value  with the result found by the previous \\nresearches mentioned in Table 1, we have earned the highest \\nscore with 89. 57 at tributed to Random Forest.  Moreover , we \\ncan also conclude that the performance evaluation method for \\na classificati on model based on the (Van Rijsberjen, 1979)  \\napproach using its F -Measure formula is outdated, the method \\nshould be upgraded or replaced with  the (Nakache & Metas, \\n2005)  approach.  \\nIn real life, accusing an insured of fraud is a grave act, the \\nclient risks not being indemnified for a probability of a claim \\nsuspected fraudulent , such probability depending on the result \\nand performance of the classification model chosen . \\nRandomForest has the best score in our case study, but the \\ninsurance companies are more prudent,  as they can only open \\na litigation process for the piece of evidence  and not on a \\nprobability basis . Otherwise, this can compromise the \\ninsurer\\'s image and reputation, or even generate other indirect \\ncosts.  \\nACKNOWLEDGMENT  \\n \\nThis project has received funding from the European \\nUnionâ€™s Horizon 2020 research and innovation programme \\nunder the Marie SkÅ‚odowska -Curie grant agreemen t No \\n777720.  \\nREFERENCES  \\n \\n[1] Richard J. Bolton and David J. Statistical Fraud Detection: A Review  . \\nHand Statistical Science Vol. 17, No. 3 (Aug., 2002), pp. 235 -249.  [2] Allen, T. (2000), A day in the life of a Medicaid fraud statistician. \\nSTATS 29, 20 - 22. \\n[3] Tenn yson Sharon, Salsas -Forn Pau. Claims auditing in automobile \\ninsurance: fraud detection and deterrence objectives. Journal of Risk & \\nInsurance, Vol. 69, pp. 289 -308, 2002.   \\n[4] A. Derrig Richard, Insurance fraud, J  Risk Insur,  69 (2002), pp.  271-\\n287. \\n[5] Cutting co rners, August 2015. Cutting corners to get cheaper motor \\ninsurance backfiring on thous ands of motorists warns the ABI.   \\n[6] Stolfo, S.J., Prodromidis, A.L., Tselepis, S., Lee, W., Fan, D.W., \\n1997a. JAM: Java agents for meta -learning over distributed databases.  \\nAAAI Workshop on AI Approaches to Fraud Detection. In: \\nProceedings of the 3rd International Conference Knowledge Discovery \\nand Data Mining, pp. 74 â€“81. \\n[7] Stolfo, S.J., Fan, D.W., Lee, W., Prodromidis, A.L., Chan, P., 2000. \\nCost-based modeling for fraud and i ntrusion detection: results from the \\nJAM project. In: Proceedings of the DARPA Information Survivability \\nConference and Exposition (DISCEXâ€˜2000), vol. 2, pp. 130 â€“144. \\n[8] Artis, M., M. Ayuso, and M. Guillen, 2002, Detection of Automobile \\nInsurance Fraud With D iscrete Choice Models and Misclassified \\nClaims, Journal of Risk and Insurance, Vol. 69,pp. 325 -340.  \\n[9]  Phua, C., Alahakoon, D., Lee, V., 2004. Minority report in fraud \\ndetection: classification of skewed data. Acm Sigkdd Explor. Newslett. \\n6 (1), 50 â€“59. \\n[10] Pathak, J., Vidyarthi, N., Summers, S.L., 2005. A fuzzy -based \\nalgorithm for auditors to detect elements of fraud in settled insurance \\nclaims. Managerial Auditing J. 20 (6), 632 â€“644.  \\n[11] J. Pinquet, M. Ayuso, and M. Guillen, \"Selection bias and auditing'),\n",
       " Document(metadata={'source': 'IEEEComparativeStudy.pdf', 'page': 1}, page_content='to improve perfo rmance. In 2000, Stolf o et al.  [7] proposed \\nCost-based metrics to train and evaluate the performance of \\nlearning systems for fraud detection in financial information \\nsystems.  Artis et al, (2002 ) [8] demonstrate d the performance \\nof binary choice models for fraud  detection of Au tomobile \\nInsurance Fraud and implements models for misclassification \\nassumptions in logistic regression mode . Phua et al. (2004 ) [9] \\npropose d a meta -learning approach by  hybridizing bagging \\nand stacking together, comparing too appro ach for the fraud \\ndetect ion training, meta -learning approach against simpling \\napproach.  Pathak et al.  (2005 ) [10] used the fuzzy logic -based \\nlogic system to find  such types  of frauds in insurance claims \\nsettlement.  Pinquet et al.  (2007 ) [11] suggest ed a statistical \\napproach for fraud risk models, developing  a two-equation \\nmodel that applied to a real dataset of Spanish insurance \\ncompany . BermÃºdez et al. ( 2008 ) [12] Suggest ed the naive \\nBayes dichotomous model with asymmetric  or skewed logit \\nlink to detect fraud  from  the Spanish insurance market  \\ndatabase. In 2011, Xu et al. [13] propose d a random  rough \\nsubspace based neural network ensemble for insurance fraud \\ndetection, and used rough set reduction  to improve the \\nconsistency in the Insurance Company datasets . Tao et al. \\n(2012 ) [14] projected Insurance Fraud Identification Research \\nBased on  a Fuzzy Support Vector Machine with Dual \\nMembership, for \"overlap\" problem s in insurance fraud \\nsamples. Benard and Vanduffel (2014) [ 15] studied mean -\\nvariance optim al portfolios and suggest ed method to \\nmaximize the measure balancing risk (Sharpe ratios),  they \\ndemonstr ated how results can be used in fr aud detection . \\nSundarkumar and Ravi (2015 ) [16] propose d an hybrid \\napproach for rectifying the data imbalance problem by \\nemploying k Reverse Nearest Neighborhood and one class')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "retriever.invoke(\"why Radom  Forest is better ? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moperator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m itemgetter\n\u001b[1;32m      3\u001b[0m chain \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      4\u001b[0m     {\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: itemgetter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m|\u001b[39m retriever,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m|\u001b[39m parser\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhy Radom  Forest is better ? \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain_core/runnables/base.py:2876\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2874\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m   2875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2876\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2877\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2878\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain_core/runnables/base.py:3580\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   3575\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3576\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3577\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[1;32m   3578\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3579\u001b[0m         ]\n\u001b[0;32m-> 3580\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3581\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3582\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain_core/runnables/base.py:3580\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3575\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3576\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3577\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[1;32m   3578\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3579\u001b[0m         ]\n\u001b[0;32m-> 3580\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3581\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3582\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain_core/runnables/base.py:3564\u001b[0m, in \u001b[0;36mRunnableParallel.invoke.<locals>._invoke_step\u001b[0;34m(step, input, config, key)\u001b[0m\n\u001b[1;32m   3562\u001b[0m context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   3563\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m-> 3564\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3566\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchild_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3568\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain_core/runnables/base.py:2876\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2874\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m   2875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2876\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2877\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2878\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain_core/runnables/base.py:4475\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4461\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[1;32m   4462\u001b[0m \n\u001b[1;32m   4463\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4472\u001b[0m \u001b[38;5;124;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[1;32m   4473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4476\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4477\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4478\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4479\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4480\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4481\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4482\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   4483\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4484\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4485\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain_core/runnables/base.py:1785\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1782\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1783\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1784\u001b[0m         Output,\n\u001b[0;32m-> 1785\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1788\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1793\u001b[0m     )\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1795\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain_core/runnables/config.py:397\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    396\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain_core/runnables/base.py:4331\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   4329\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[1;32m   4330\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4331\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4332\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   4333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4334\u001b[0m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[1;32m   4335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain_core/runnables/config.py:397\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    396\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "chain.invoke(\"why Radom  Forest is better ? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
